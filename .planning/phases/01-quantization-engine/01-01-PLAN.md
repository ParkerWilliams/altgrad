---
phase: 01-quantization-engine
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - altgrad/quantization/__init__.py
  - altgrad/quantization/formats.py
  - tests/test_formats.py
autonomous: true

must_haves:
  truths:
    - "Each FP8 format (E0M7, E1M6, E3M4, E5M2, E7M0) correctly encodes values to 8-bit representation"
    - "Each FP8 format correctly decodes 8-bit representation back to real values"
    - "Round-trip (encode -> decode) preserves values within format's representable range"
    - "Transfer functions map all 256 bit-indices to correct real values"
  artifacts:
    - path: "altgrad/quantization/formats.py"
      provides: "FP8 format registry and transfer functions"
      exports: ["FP8Format", "E0M7", "E1M6", "E3M4", "E5M2", "E7M0", "FORMAT_REGISTRY"]
    - path: "altgrad/quantization/__init__.py"
      provides: "Package exports"
      exports: ["FP8Format", "E0M7", "E1M6", "E3M4", "E5M2", "E7M0"]
    - path: "tests/test_formats.py"
      provides: "Format correctness tests"
      min_lines: 100
  key_links:
    - from: "altgrad/quantization/formats.py"
      to: "FP8Format dataclass"
      via: "format specification fields"
      pattern: "exponent_bits.*mantissa_bits.*bias"
    - from: "tests/test_formats.py"
      to: "altgrad/quantization/formats.py"
      via: "import and test"
      pattern: "from altgrad.quantization.formats import"
---

<objective>
Implement FP8 format registry with bit-level transfer functions using TDD.

Purpose: Establish the mathematical foundation for all FP8 quantization. Each format's bit-index <-> real value mapping must be precisely correct before any quantization logic can be built on top.

Output: `altgrad/quantization/formats.py` with 5 FP8 format specifications and their transfer functions, validated by comprehensive tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md

# FP8 Format Mathematics

Each FP8 format splits 8 bits into sign (1), exponent (E), mantissa (M):
- E0M7: sign + 0 exponent + 7 mantissa = fixed-point, range [-1, 1)
- E1M6: sign + 1 exponent + 6 mantissa = two scales (0.5x, 1x)
- E3M4: sign + 3 exponent + 4 mantissa = moderate range (~0.015 to 240)
- E5M2: sign + 5 exponent + 2 mantissa = standard FP8, wide range (~1e-9 to 57344)
- E7M0: sign + 7 exponent + 0 mantissa = powers of 2 only (extreme test case)

Transfer function: bit_index (0-255) -> real value
- For normalized numbers: (-1)^s * 2^(e-bias) * (1 + m/2^M)
- For denormalized (e=0): (-1)^s * 2^(1-bias) * (m/2^M)
- Special cases: NaN, Inf (only in formats with enough exponent bits)

Inverse transfer: real value -> bit_index (with rounding)
</context>

<feature>
  <name>FP8 Format Registry</name>
  <files>altgrad/quantization/formats.py, tests/test_formats.py</files>
  <behavior>
    FP8Format dataclass stores: name, exponent_bits, mantissa_bits, bias, has_inf, has_nan

    to_real(bit_index: int) -> float:
      - E5M2: to_real(0b01000000) = 1.0 (exponent=8, bias=15, e-bias=-7, but actually e=16 means 1.0)
      - E5M2: to_real(0b00000001) = smallest denorm
      - E7M0: to_real(0b01000000) = 1.0 (e=64, bias=63)
      - E0M7: to_real(0b00000001) = 1/128

    to_bits(value: float) -> int:
      - Inverse of to_real with round-to-nearest-even
      - Clamps to representable range
      - Returns correct bit pattern

    Round-trip property: to_real(to_bits(x)) == x for representable x
  </behavior>
  <implementation>
    1. Create FP8Format frozen dataclass with format specs
    2. Implement to_real() handling: sign extraction, exponent decoding, mantissa assembly, denorm detection
    3. Implement to_bits() handling: sign, find exponent, compute mantissa, round, assemble
    4. Define 5 format constants (E0M7, E1M6, E3M4, E5M2, E7M0) with correct bias values
    5. Create FORMAT_REGISTRY dict for lookup by name
  </implementation>
</feature>

<verification>
```bash
# Run format tests
python -m pytest tests/test_formats.py -v

# Verify all 5 formats registered
python -c "from altgrad.quantization.formats import FORMAT_REGISTRY; print(list(FORMAT_REGISTRY.keys()))"
```
</verification>

<success_criteria>
1. All format tests pass (round-trip, boundary values, special cases)
2. Each of 5 formats correctly maps 256 bit-indices to real values
3. to_bits() correctly inverts to_real() for representable values
4. E7M0 produces only powers of 2 (no mantissa interpolation)
5. E0M7 produces only fixed-point values in [-1, 1)
</success_criteria>

<output>
After completion, create `.planning/phases/01-quantization-engine/01-01-SUMMARY.md`
</output>
