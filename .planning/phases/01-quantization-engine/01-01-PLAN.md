---
phase: 01-quantization-engine
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - altgrad/quantization/__init__.py
  - altgrad/quantization/formats.py
  - tests/test_formats.py
autonomous: true

must_haves:
  truths:
    - "Each FP8 format (E0M7, E1M6, E3M4, E5M2, E7M0) correctly encodes values to 8-bit representation"
    - "Each FP8 format correctly decodes 8-bit representation back to real values"
    - "Round-trip (encode -> decode) preserves values within format's representable range"
    - "Transfer functions map all 256 bit-indices to correct real values"
  artifacts:
    - path: "altgrad/quantization/formats.py"
      provides: "FP8 format registry and transfer functions"
      exports: ["FP8Format", "E0M7", "E1M6", "E3M4", "E5M2", "E7M0", "FORMAT_REGISTRY"]
      min_lines: 180
    - path: "altgrad/quantization/__init__.py"
      provides: "Package exports"
      exports: ["FP8Format", "E0M7", "E1M6", "E3M4", "E5M2", "E7M0"]
    - path: "tests/test_formats.py"
      provides: "Format correctness tests"
      min_lines: 100
  key_links:
    - from: "altgrad/quantization/formats.py"
      to: "FP8Format dataclass"
      via: "format specification fields"
      pattern: "exponent_bits.*mantissa_bits.*bias"
    - from: "tests/test_formats.py"
      to: "altgrad/quantization/formats.py"
      via: "import and test"
      pattern: "from altgrad.quantization.formats import"
---

<objective>
Implement FP8 format registry with bit-level transfer functions using TDD.

Purpose: Establish the mathematical foundation for all FP8 quantization. Each format's bit-index <-> real value mapping must be precisely correct before any quantization logic can be built on top.

Output: `altgrad/quantization/formats.py` with 5 FP8 format specifications and their transfer functions, validated by comprehensive tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md

# FP8 Format Mathematics

Each FP8 format splits 8 bits into sign (1), exponent (E), mantissa (M):
- E0M7: sign + 0 exponent + 7 mantissa = fixed-point, range [-1, 1)
- E1M6: sign + 1 exponent + 6 mantissa = two scales (0.5x, 1x)
- E3M4: sign + 3 exponent + 4 mantissa = moderate range (~0.015 to 240)
- E5M2: sign + 5 exponent + 2 mantissa = standard FP8, wide range (~1e-9 to 57344)
- E7M0: sign + 7 exponent + 0 mantissa = powers of 2 only (extreme test case)

Transfer function: bit_index (0-255) -> real value
- For normalized numbers: (-1)^s * 2^(e-bias) * (1 + m/2^M)
- For denormalized (e=0): (-1)^s * 2^(1-bias) * (m/2^M)
- Special cases: NaN, Inf (only in formats with enough exponent bits)

Inverse transfer: real value -> bit_index (with rounding)
</context>

<tasks>

<task type="tdd">
  <name>Task 1: Write failing tests for FP8 formats</name>
  <files>tests/test_formats.py</files>
  <action>
    Create tests/test_formats.py with comprehensive test cases BEFORE implementation.

    Create test directory if needed: mkdir -p tests

    Test structure:
    1. test_fp8format_dataclass_fields(): verify FP8Format has name, exponent_bits, mantissa_bits, bias, has_inf, has_nan
    2. test_format_registry_contains_all(): verify FORMAT_REGISTRY has E0M7, E1M6, E3M4, E5M2, E7M0
    3. test_e5m2_to_real_known_values():
       - to_real(0b00111100) == 1.0 (exponent=15, bias=15)
       - to_real(0b00000001) == smallest denorm (~5.96e-8)
       - to_real(0b01111011) == 57344 (max finite)
       - to_real(0b10111100) == -1.0 (negative)
    4. test_e7m0_to_real_powers_of_two():
       - to_real(0b00111111) == 1.0 (e=63, bias=63)
       - to_real(0b01000000) == 2.0
       - to_real(0b00111110) == 0.5
       - All outputs are exact powers of 2
    5. test_e0m7_to_real_fixed_point():
       - to_real(0b00000001) == 1/128
       - to_real(0b01111111) == 127/128
       - All values in [-1, 1)
    6. test_to_bits_inverts_to_real():
       - For each format, for representable values: to_real(to_bits(x)) == x
    7. test_to_bits_rounds_correctly():
       - Values between representable points round to nearest
    8. test_to_bits_clamps_out_of_range():
       - Values above max clamp to max (or inf if format has it)
       - Values below min clamp to zero or min denorm

    Tests MUST fail initially (formats.py doesn't exist yet).
  </action>
  <verify>python -m pytest tests/test_formats.py -v 2>&1 | grep -E "(FAILED|ERROR|passed)" (expect failures)</verify>
  <done>Test file exists with comprehensive test cases, all tests fail due to missing implementation</done>
</task>

<task type="tdd">
  <name>Task 2: Implement FP8 formats to pass tests</name>
  <files>altgrad/quantization/formats.py, altgrad/quantization/__init__.py</files>
  <action>
    Create directory structure: mkdir -p altgrad/quantization

    Create altgrad/quantization/formats.py with:

    1. FP8Format frozen dataclass:
       - name: str
       - exponent_bits: int
       - mantissa_bits: int
       - bias: int
       - has_inf: bool = False
       - has_nan: bool = False
       - max_representable_value property (computed from format params)

    2. to_real(self, bit_index: int) -> float method:
       - Extract sign bit: s = (bit_index >> 7) & 1
       - Extract exponent: e = (bit_index >> mantissa_bits) & ((1 << exponent_bits) - 1)
       - Extract mantissa: m = bit_index & ((1 << mantissa_bits) - 1)
       - Handle E0M7 special case (no exponent, pure fixed-point)
       - Handle denormalized (e=0): value = 2^(1-bias) * (m / 2^M)
       - Handle normalized: value = 2^(e-bias) * (1 + m / 2^M)
       - Handle special values (inf, nan) if format supports
       - Apply sign: return -value if s else value

    3. to_bits(self, value: float) -> int method:
       - Handle sign: s = 1 if value < 0 else 0; value = abs(value)
       - Handle zero: return 0 (or 0x80 for negative zero)
       - Handle E0M7 special case: direct fixed-point conversion
       - Find exponent: e = floor(log2(value)) + bias
       - Clamp exponent to valid range
       - Compute mantissa with rounding: m = round((value / 2^(e-bias) - 1) * 2^M)
       - Handle denormalized if e would be negative
       - Assemble: (s << 7) | (e << mantissa_bits) | m
       - Apply round-to-nearest-even for ties

    4. Define format constants:
       - E0M7 = FP8Format("E0M7", 0, 7, 0, False, False)
       - E1M6 = FP8Format("E1M6", 1, 6, 0, False, False)
       - E3M4 = FP8Format("E3M4", 3, 4, 7, False, False)
       - E5M2 = FP8Format("E5M2", 5, 2, 15, True, True)
       - E7M0 = FP8Format("E7M0", 7, 0, 63, False, False)

    5. FORMAT_REGISTRY = {"E0M7": E0M7, "E1M6": E1M6, ...}

    Create altgrad/quantization/__init__.py:
       - from .formats import FP8Format, E0M7, E1M6, E3M4, E5M2, E7M0, FORMAT_REGISTRY
       - __all__ = ["FP8Format", "E0M7", "E1M6", "E3M4", "E5M2", "E7M0", "FORMAT_REGISTRY"]

    Run tests iteratively until all pass.
  </action>
  <verify>python -m pytest tests/test_formats.py -v (all tests must pass)</verify>
  <done>All format tests pass, round-trip property holds for all 5 formats</done>
</task>

</tasks>

<verification>
```bash
# Run format tests
python -m pytest tests/test_formats.py -v

# Verify all 5 formats registered
python -c "from altgrad.quantization.formats import FORMAT_REGISTRY; print(list(FORMAT_REGISTRY.keys()))"
```
</verification>

<success_criteria>
1. All format tests pass (round-trip, boundary values, special cases)
2. Each of 5 formats correctly maps 256 bit-indices to real values
3. to_bits() correctly inverts to_real() for representable values
4. E7M0 produces only powers of 2 (no mantissa interpolation)
5. E0M7 produces only fixed-point values in [-1, 1)
</success_criteria>

<output>
After completion, create `.planning/phases/01-quantization-engine/01-01-SUMMARY.md`
</output>
