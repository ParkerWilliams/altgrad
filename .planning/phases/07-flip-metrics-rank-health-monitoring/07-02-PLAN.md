---
phase: 07-flip-metrics-rank-health-monitoring
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - altgrad/quantization/rank_health.py
  - altgrad/quantization/__init__.py
  - altgrad/training/metrics.py
  - tests/test_rank_health.py
autonomous: true

must_haves:
  truths:
    - "Stable rank computes ||W||_F^2 / ||W||_2^2 for weight matrices"
    - "Effective rank computes exp(entropy) of normalized singular values"
    - "Rank collapse early warning detects sustained downward trends via EMA"
    - "Per-layer rank metrics log to existing metrics aggregation pattern"
  artifacts:
    - path: "altgrad/quantization/rank_health.py"
      provides: "compute_stable_rank, compute_effective_rank, RankTrendDetector, RankHealthMonitor"
      exports: ["compute_stable_rank", "compute_effective_rank", "RankTrendDetector", "RankHealthMonitor"]
    - path: "tests/test_rank_health.py"
      provides: "Unit tests for rank health"
      contains: "def test_"
  key_links:
    - from: "altgrad/quantization/rank_health.py"
      to: "torch.linalg.svdvals"
      via: "SVD computation"
      pattern: "torch\\.linalg\\.svdvals"
    - from: "altgrad/training/metrics.py"
      to: "altgrad/quantization/rank_health.py"
      via: "compute_rank_stats function"
      pattern: "from altgrad\\.quantization\\.rank_health import"
---

<objective>
Implement stable rank, effective rank, and rank collapse early warning for monitoring weight matrix health during training.

Purpose: Track matrix rank degradation during quantized training. Stable rank (||W||_F^2 / ||W||_2^2) and effective rank (exp of normalized SV entropy) are complementary measures. Early warning via EMA trend detection catches collapse before catastrophic failure.

Output: `rank_health.py` module with rank computation functions and monitoring classes, plus metrics.py integration and unit tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-flip-metrics-rank-health-monitoring/07-RESEARCH.md

# Existing patterns to follow
@altgrad/training/metrics.py
@altgrad/quantization/diagnostics.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create rank_health.py with rank computation functions</name>
  <files>altgrad/quantization/rank_health.py</files>
  <action>
Create `altgrad/quantization/rank_health.py` with:

1. **compute_stable_rank(weight: Tensor) -> float**:
   - Compute stable rank = ||W||_F^2 / ||W||_2^2 = sum(s_i^2) / s_1^2
   - Reshape to 2D if needed: `weight.view(weight.size(0), -1)` for conv weights
   - Use `torch.linalg.svdvals(weight)` for efficient singular values only
   - Handle zero matrix: return float(weight.numel()) as fallback
   - Return scalar float

2. **compute_effective_rank(weight: Tensor, eps: float = 1e-10) -> float**:
   - Compute effective rank = exp(-sum(p_i * log(p_i)))
   - Where p_i = s_i / sum(s_j) are normalized singular values
   - Reshape to 2D if needed
   - Use `torch.linalg.svdvals(weight)`
   - Handle degenerate case (sv_sum < eps): return 1.0
   - Return scalar float in range [1, min(m,n)]

3. **RankTrendDetector class** - EMA-based trend detection:
   - `__init__(alpha: float = 0.1, threshold_pct: float = 0.2, window: int = 100)`:
     - alpha: EMA smoothing factor (lower = slower adaptation)
     - threshold_pct: Warn if EMA drops by this fraction from initial
     - window: Steps before trend detection activates
   - `update(value: float) -> Optional[str]`: Update with new rank value, return warning string if trend detected, else None
   - `reset()`: Clear state

4. **RankHealthMonitor class** - per-layer monitoring:
   - `__init__(log_interval: int = 100, warn_threshold: float = 0.3, critical_layers: Optional[List[str]] = None)`:
     - log_interval: Compute rank every N steps
     - warn_threshold: Fraction drop that triggers warning
     - critical_layers: Layer name patterns to prioritize (default: ["lm_head", "c_proj"])
   - `compute_layer_ranks(model: nn.Module) -> Dict[str, Dict[str, float]]`: Compute stable_rank, effective_rank, spectral_norm for all 2D+ params
   - `check_warnings(ranks: Dict) -> List[str]`: Check for rank collapse warnings using internal RankTrendDetectors

Follow patterns from research:
- Use `torch.linalg.svdvals()` not full SVD (10-50x faster)
- Reshape conv weights to 2D before SVD
- EMA warmup before trend detection

Include comprehensive docstrings with examples.
  </action>
  <verify>
```bash
cd /Users/prwilliams/Repos/altgrad && python -c "
from altgrad.quantization.rank_health import (
    compute_stable_rank, compute_effective_rank,
    RankTrendDetector, RankHealthMonitor
)
import torch

# Test rank functions
w = torch.randn(64, 128)
sr = compute_stable_rank(w)
er = compute_effective_rank(w)
print(f'Stable rank: {sr:.2f}, Effective rank: {er:.2f}')

# Test trend detector
detector = RankTrendDetector()
print(f'RankTrendDetector instantiated')

# Test monitor
monitor = RankHealthMonitor()
print(f'RankHealthMonitor instantiated')
"
```
  </verify>
  <done>All rank health functions and classes instantiate, compute_stable_rank and compute_effective_rank return reasonable values for random matrices</done>
</task>

<task type="auto">
  <name>Task 2: Add compute_rank_stats to metrics.py and exports</name>
  <files>altgrad/training/metrics.py, altgrad/quantization/__init__.py</files>
  <action>
1. **Update `altgrad/training/metrics.py`**:

Add a new function `compute_rank_stats(model: nn.Module) -> Dict[str, float]` that:
- Iterates over model.named_parameters()
- Skips parameters with dim < 2 (biases, LayerNorm scales)
- For each 2D+ parameter, computes stable_rank and effective_rank
- Returns dict with keys:
  - `stable_rank/{name}`: Per-layer stable rank
  - `effective_rank/{name}`: Per-layer effective rank
  - `stable_rank/mean`: Mean stable rank across layers
  - `effective_rank/mean`: Mean effective rank across layers
  - `stable_rank/min`: Minimum stable rank (collapse indicator)
  - `effective_rank/min`: Minimum effective rank

Follow the pattern from `compute_gradient_stats()` in the same file.

Add import at top:
```python
from altgrad.quantization.rank_health import compute_stable_rank, compute_effective_rank
```

Add to `__all__`: `"compute_rank_stats"`

2. **Update `altgrad/quantization/__init__.py`**:
   - Add imports: `from altgrad.quantization.rank_health import compute_stable_rank, compute_effective_rank, RankTrendDetector, RankHealthMonitor`
   - Add to `__all__`: all four exports
  </action>
  <verify>
```bash
cd /Users/prwilliams/Repos/altgrad && python -c "
from altgrad.training.metrics import compute_rank_stats
from altgrad.quantization import compute_stable_rank, compute_effective_rank, RankTrendDetector, RankHealthMonitor
import torch.nn as nn

# Test compute_rank_stats
model = nn.Sequential(nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 10))
stats = compute_rank_stats(model)
print(f'Keys: {list(stats.keys())[:5]}...')
print(f'stable_rank/mean: {stats.get(\"stable_rank/mean\", \"MISSING\")}')
"
```
  </verify>
  <done>compute_rank_stats returns per-layer and aggregate rank metrics, all exports available from altgrad.quantization</done>
</task>

<task type="auto">
  <name>Task 3: Create unit tests for rank health</name>
  <files>tests/test_rank_health.py</files>
  <action>
Create `tests/test_rank_health.py` with comprehensive tests:

```python
"""Tests for rank health monitoring."""
import pytest
import torch
import torch.nn as nn
from altgrad.quantization.rank_health import (
    compute_stable_rank, compute_effective_rank,
    RankTrendDetector, RankHealthMonitor
)
from altgrad.training.metrics import compute_rank_stats


class TestStableRank:
    def test_identity_matrix_full_rank(self):
        """Identity matrix has stable rank equal to dimension."""
        eye = torch.eye(10)
        sr = compute_stable_rank(eye)
        assert abs(sr - 10.0) < 0.1  # Should be exactly 10

    def test_rank_one_matrix(self):
        """Rank-1 matrix has stable rank 1."""
        u = torch.randn(10, 1)
        v = torch.randn(1, 5)
        rank1 = u @ v  # Outer product
        sr = compute_stable_rank(rank1)
        assert abs(sr - 1.0) < 0.1

    def test_random_matrix_intermediate_rank(self):
        """Random matrix has intermediate stable rank."""
        w = torch.randn(64, 128)
        sr = compute_stable_rank(w)
        assert 1.0 <= sr <= 64.0  # Between 1 and min(m,n)


class TestEffectiveRank:
    def test_identity_matrix_full_rank(self):
        """Identity matrix has effective rank equal to dimension."""
        eye = torch.eye(10)
        er = compute_effective_rank(eye)
        assert abs(er - 10.0) < 0.1

    def test_rank_one_matrix(self):
        """Rank-1 matrix has effective rank close to 1."""
        u = torch.randn(10, 1)
        v = torch.randn(1, 5)
        rank1 = u @ v
        er = compute_effective_rank(rank1)
        assert er < 2.0  # Should be close to 1

    def test_effective_rank_bounded(self):
        """Effective rank is bounded by matrix dimensions."""
        w = torch.randn(32, 64)
        er = compute_effective_rank(w)
        assert 1.0 <= er <= 32.0


class TestRankTrendDetector:
    def test_no_warning_during_warmup(self):
        """No warnings during warmup window."""
        detector = RankTrendDetector(window=10)
        for i in range(10):
            warning = detector.update(10.0 - i * 0.5)  # Dropping rank
            assert warning is None  # Still in warmup

    def test_warning_on_sustained_drop(self):
        """Warning issued on sustained rank drop after warmup."""
        detector = RankTrendDetector(window=10, threshold_pct=0.2, alpha=0.3)
        # Warmup with stable values
        for _ in range(15):
            detector.update(10.0)
        # Now drop significantly
        warning = None
        for _ in range(20):
            warning = detector.update(5.0)
            if warning:
                break
        assert warning is not None
        assert "WARN" in warning or "drop" in warning.lower()

    def test_reset_clears_state(self):
        """reset() clears all tracking state."""
        detector = RankTrendDetector()
        for _ in range(5):
            detector.update(10.0)
        detector.reset()
        assert detector.ema is None
        assert detector.step_count == 0


class TestRankHealthMonitor:
    def test_compute_layer_ranks(self):
        """compute_layer_ranks returns valid metrics for model."""
        model = nn.Linear(64, 32)
        monitor = RankHealthMonitor()
        ranks = monitor.compute_layer_ranks(model)

        assert len(ranks) == 1  # One weight matrix
        for name, metrics in ranks.items():
            assert "stable_rank" in metrics
            assert "effective_rank" in metrics
            assert "spectral_norm" in metrics

    def test_skips_1d_params(self):
        """1D parameters (biases) are skipped."""
        model = nn.Linear(64, 32, bias=True)
        monitor = RankHealthMonitor()
        ranks = monitor.compute_layer_ranks(model)

        # Should only have weight, not bias
        assert len(ranks) == 1


class TestComputeRankStats:
    def test_returns_aggregate_stats(self):
        """compute_rank_stats returns per-layer and aggregate metrics."""
        model = nn.Sequential(
            nn.Linear(64, 32),
            nn.Linear(32, 10)
        )
        stats = compute_rank_stats(model)

        assert "stable_rank/mean" in stats
        assert "effective_rank/mean" in stats
        assert "stable_rank/min" in stats
        assert "effective_rank/min" in stats
```

Run tests to verify all pass.
  </action>
  <verify>
```bash
cd /Users/prwilliams/Repos/altgrad && python -m pytest tests/test_rank_health.py -v
```
  </verify>
  <done>All rank health tests pass, covering stable rank, effective rank, trend detection, and metrics integration</done>
</task>

</tasks>

<verification>
1. Rank functions: `compute_stable_rank(eye(10))` returns ~10, `compute_effective_rank(eye(10))` returns ~10
2. Trend detector: Warns on sustained drop after warmup
3. All tests pass: `pytest tests/test_rank_health.py -v`
4. Integration: `compute_rank_stats(model)` returns per-layer and aggregate metrics
</verification>

<success_criteria>
- compute_stable_rank correctly computes ||W||_F^2 / ||W||_2^2
- compute_effective_rank correctly computes exp(entropy) of normalized SVs
- RankTrendDetector warns on sustained downward trends after warmup
- RankHealthMonitor computes per-layer ranks for any model
- compute_rank_stats integrates with existing metrics pattern in training/metrics.py
- All unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/07-flip-metrics-rank-health-monitoring/07-02-SUMMARY.md`
</output>
